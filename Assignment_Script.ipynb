{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e88d97d",
   "metadata": {},
   "source": [
    "# Analysing artisanal small-scale mining in the DRC between 2013 and 2022 via NDVI and Sentinel 2A imagery "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a261b5",
   "metadata": {},
   "source": [
    "This code analyses changes in artisanal small-scale (ASM) mining activity at an illegal mining site in Bisie in the DR Congo (DRC) between the years 2016 and 2022. While ASM provides a livelihood to more than 45m peoples globally, it also is associated with financing military conflict groups and with environmental degradation, such as deforestation and mercury pollution. \n",
    "\n",
    "This code calculates the NDVI for Sentinel 2A imagery as well as the change of the NDVI between the years 2016 and 2022. Prior to the NDVI calculation, the code first loads and reads the imagery into memory, inspects several key characteristics of the imagery, and displays the False Colour Composite of the imagery for both years.\n",
    "\n",
    "First, we start by importing the necessary modules:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72d5b1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "import numpy as np\n",
    "import rasterio as rio\n",
    "from rasterio import plot \n",
    "import cartopy.crs as ccrs\n",
    "import matplotlib.pyplot as plt\n",
    "from rasterio.plot import show\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e4bd8e",
   "metadata": {},
   "source": [
    "Now, we open the datasets and load the imageries into the memory. We load all bands of the imagery, that is, band1(blue), band2(green), band3(red) and band8(NIR). If you were to load only one particular band, you would need to specify the number of the band in the read() method. For instance, for loading only band8(NIR), you would need to modify the code as, e.g. img16 = dataset16.read(3). Be careful: in the read() method, indices start from 1, not from 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0dd06073",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opens the files from 2016 and 2022\n",
    "dataset16 = rio.open(\"D://RS_Ulster//sub_16.tif\")\n",
    "dataset22 = rio.open(\"D://RS_Ulster//sub_22.tif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3249ff37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loads the raster imageries into memory; \n",
    "img16 = dataset16.read()\n",
    "img22 = dataset22.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de948c75",
   "metadata": {},
   "source": [
    "Next, we verify the metadata as well as some of the attribues from the datasets and loaded images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40b68cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#verifies the datasets´ meta-data, including the driver, datatype, width, height, crs and layer count of the dataset\n",
    "print('the 2016 dataset´s metadata is:  {}'.format(dataset16.meta))\n",
    "print('the 2022 dataset´s metadata is:  {}'.format(dataset22.meta))\n",
    "\n",
    "#alternatively, we could also verify these informations via the following methods, such as, for instance:\n",
    "dataset16.height #number of columns\n",
    "dataset16.width #number of rows\n",
    "dataset16.crs #coordinate reference system\n",
    "dataset16.count #number of layers/bands\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3954d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#verifies the datasets´ Bounding Box\n",
    "print('for 2016: {}'.format(dataset16.bounds))\n",
    "print('for 2022: {}'.format(dataset22.bounds))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c80936",
   "metadata": {},
   "source": [
    "The loaded images consist of arrays with the pixel values of the particular bands. Similar to lists and tuples, these arrays can be indexed. If there are more than just one band, the first index corresponds to the band, the second to the row (y) location, and the third to the column (x). If there is only one band, the first would correspond to the row (y) location, the second to the column (x) location. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ee2728",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(img22[2]) #gets the array of pixel values for band 3 (red) for image 2022\n",
    "print(img22[2,444,344]) #gets the pixel values for band 3 (red) for row (x) of 444 and column (y) of 344 \n",
    "print(img22[3,444,344]) #gets the pixel values for band 4 (NIR) for row (x) of 444 and column (y) of 344 \n",
    "print(img22[2:,444, 344])  #gets the pixel values for band 3(red) and 4 (NIR) for row (x) of 444 and column (y) of 344 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4857313",
   "metadata": {},
   "source": [
    "In the next line, we verify the shape of the loaded imagery and verify if the shapes are the same for both bands. This is important because if the shapes were not the same, we could not perform calculations between the arrays. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c20b3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(img16.shape, img22.shape) #gets the shapes for both images \n",
    "img16.shape == img22.shape #verifies if both images have the same shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146fd851",
   "metadata": {},
   "source": [
    "In the following line, we verify both the maximum and minimum pixel value of all bands for both images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4032785c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#verifies the max pixel values for both images for all bands \n",
    "print(np.max(img16, axis=(1, 2)), np.min(img16, axis=(1, 2)))\n",
    "print(np.max(img22, axis=(1, 2)), np.min(img22, axis=(1, 2)))\n",
    "\n",
    "#alternatively, we could do it like that:\n",
    "maxvals = [img16[i].max() for i in range(dataset16.count)]\n",
    "print(maxvals)\n",
    "minvals = [img16[i].min() for i in range(dataset16.count)]\n",
    "print(minvals)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "310cd3b1",
   "metadata": {},
   "source": [
    "Now, we create a figure to plot our imagery. First, we define the CRS for both images for cartopy. As we have seen with the csr(method), both images are from EPSG 32735. In this link we can verify which coordinate reference system the EPSG corresponds to: https://epsg.io/ . Then, we set the boundaries for the imagery, for which we can use the bounds-methods. The Bounding Box is for both images the same. Finally, we establish the axes and figure size for our plot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ba0894",
   "metadata": {},
   "outputs": [],
   "source": [
    "myCRS = ccrs.UTM(35) \n",
    "xmin, ymin, xmax, ymax = dataset22.bounds #as both images have the same bounds we can just pick one year\n",
    "fig, ax = plt.subplots(1, 1, figsize=(5, 5), subplot_kw=dict(projection=myCRS))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493f3701",
   "metadata": {},
   "source": [
    "In this function, we address two problems: \n",
    "First, the read()methods loads the raster in a way in which: bands = index 1, rows = index 2, columns = index 3. However, imshow () needs the indices to be order as:  rows = index 1, columns = index 2, bands = index 3. So we need to re-order the indices by applying the tranpose() method. \n",
    "Secondly, supported array values for more than three bands must be either between 0-1 float or 0-255int. Thus, we need to also re-scale our image to have values between 0-1 (or 0-255). We do this simply by dividing our pixel values / 10000 and transforming the dtype into float. If we would have wanted the 0 -255 option, we could have also applied the following code:(255 dispimg = (255 *(img / 10000)).astype(np.uint8) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4059c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_display(image, ax, bands, transform, extent):\n",
    "    '''\n",
    "    This function first re-orders the indices by applying the transpose()method\n",
    "    Then it re-scales to values between 0 and 1 and changes the dtype to float. \n",
    "    Finally, it creates the handle to display the image with the ax.imshow() method.\n",
    "    \n",
    "    The parameters of the img_display function are the following: \n",
    "    \n",
    "    Image: loaded imagery\n",
    "    ax: axes\n",
    "    bands: bands you want to have displayed\n",
    "    extent: extent/boundaries of the imagery\n",
    "    '''\n",
    "    # first, we transpose the image to re-order the indices\n",
    "    dispimg = image.transpose([1, 2, 0])\n",
    "    \n",
    "    # next, we have to scale the image.\n",
    "    dispimg = (dispimg / 10000).astype(np.float64)\n",
    "    \n",
    "    # finally, we display the image\n",
    "    handle = ax.imshow(dispimg[:, :, bands], transform=transform, extent=extent)\n",
    "    \n",
    "    \n",
    "    return handle, ax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7626fd5",
   "metadata": {},
   "source": [
    "The next line calls the function img_display as a False Colour Composite (NIR, red, green). If you would like to display a True Colour Composite, you need to change the band numbers from [3, 2, 1] to [2, 1, 0].  The code also saves the figure as \"map1\". You can find that map1 then in your Jupyter Notebook. To display and save the imagery of year 2022, you need to change the first argument from \"img16\" to \"img22\". To save the figure for year 2022, you also need to change \"map1.png\" to \"map2.pgn\" -- otherwise it just overwrites the figure from year 2016. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fbb6a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "h, ax = img_display(img16, ax, [3,2,1], myCRS, [xmin, xmax, ymin, ymax])\n",
    "fig \n",
    "fig.savefig('map1.png', bbox_inches='tight', dpi=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee202a8",
   "metadata": {},
   "source": [
    "As you will notice, while the displaying of the images serves a first impression, both images are quite dark. That is, to see a bit more detail, we have to perform a percentile stretch so that images are displayed in a brighter way. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdea7bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def percentile_stretch(image, pmin=0., pmax=100.):\n",
    "    '''\n",
    "    This function calculates a percentile stretch for the imagery. \n",
    "    First, it makes sure that that pmin < pmax, and that they are between 0, 100 and assures that the image is only 2-dimensional\n",
    "    Secondly, it defines the minval and maxval\n",
    "    Finally, we calculate the stretch and make sure that all values below the minimum  are set to 0 and the ones above maxval to 1. \n",
    "    \n",
    "    The parameters for the function are: \n",
    "    image = imagery that you want to display\n",
    "    pmin, pmax = the min and max of the values to be displayed. percentile values are between 0 and 100.  \n",
    "    '''\n",
    "    # setting pmin < pmax to values between 0, 100\n",
    "    if not 0 <= pmin < pmax <= 100:\n",
    "        raise ValueError('0 <= pmin < pmax <= 100')\n",
    "    # raising an error if image is not 2-dimensional\n",
    "    if not image.ndim == 2:\n",
    "        raise ValueError('Image can only have two dimensions (row, column)')\n",
    "    \n",
    "    minval = np.percentile(image, pmin)\n",
    "    maxval = np.percentile(image, pmax)\n",
    "    \n",
    "    stretched = (image - minval) / (maxval - minval) # stretch the image to 0, 1\n",
    "    stretched[image < minval] = 0 # set anything less than minval to the new minimum, 0.\n",
    "    stretched[image > maxval] = 1 # set anything greater than maxval to the new maximum, 1.\n",
    "    \n",
    "    return stretched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34fb908e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_img_display(image, ax, bands, stretch_args=None, **imshow_kwargs):\n",
    "    '''\n",
    "    This function first copies the original image, setting the dtype as float. \n",
    "    Secondly, the function applies the percentile_stretch_function. \n",
    "    Finally, indices are re-ordered via the transpose()method \n",
    "    \n",
    "    The parameters of the img_display function are the following: \n",
    "    \n",
    "    Image: loaded imagery\n",
    "    ax: axes\n",
    "    bands: bands you want to have displayed\n",
    "    extent & transform are epxressed as args (None) and **kwargs\n",
    "    '''\n",
    "    dispimg = image.copy().astype(np.float32) # make a copy of the original image,\n",
    "    # but be sure to cast it as a floating-point image, rather than an integer\n",
    "\n",
    "    for b in range(image.shape[0]): # loop over each band, stretching using percentile_stretch()\n",
    "        if stretch_args is None: # if stretch_args is None, use the default values for percentile_stretch\n",
    "            dispimg[b] = percentile_stretch(image[b])\n",
    "        else:\n",
    "            dispimg[b] = percentile_stretch(image[b], **stretch_args)\n",
    "\n",
    "    # next, we transpose the image to re-order the indices\n",
    "    dispimg = dispimg.transpose([1, 2, 0])\n",
    "    \n",
    "    # finally, we display the image\n",
    "    handle = ax.imshow(dispimg[:, :, bands], **imshow_args)\n",
    "    \n",
    "    return handle, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4a66b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_kwargs = {'extent': [xmin, xmax, ymin, ymax],\n",
    "             'transform': myCRS}\n",
    "\n",
    "my_stretch = {'pmin': 0.1, 'pmax': 99.9}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a056c4e",
   "metadata": {},
   "source": [
    "The next line calls the function new_img_display for a False Colour composite (Nir, red, green) and saves the figure as \"map3.pgn\" For displaying a True Colour composite, you need to change the bands to [2,1,0]. \n",
    "For displaying the imagery for year 2022, you need to change the first paramter of the function from \"img16\" to \"img22\". Again, remember to also change the name of the map before saving the figure for year 2022.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ec65f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "h, ax = new_img_display(img16, ax, [3, 2, 1], stretch_args=my_stretch, **my_kwargs)\n",
    "fig\n",
    "fig.savefig('map2.png', bbox_inches='tight', dpi=200)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93eb4a49",
   "metadata": {},
   "source": [
    "Now that we have inspected both images visually, we can perform our NDVI calculation. As a first step, we have to re-scale both images to make sure the pixel values are between 0 and 1 as well as floats (fractions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f319729",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'img16' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#scales the images to a value between 0 and 1\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m img16_scaled \u001b[38;5;241m=\u001b[39m (\u001b[43mimg16\u001b[49m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m10000\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat64)\n\u001b[0;32m      3\u001b[0m img22_scaled \u001b[38;5;241m=\u001b[39m (img22\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m10000\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat64)\n\u001b[0;32m      5\u001b[0m img16_scaled\u001b[38;5;241m.\u001b[39mdtype\n",
      "\u001b[1;31mNameError\u001b[0m: name 'img16' is not defined"
     ]
    }
   ],
   "source": [
    "#scales the images to a value between 0 and 1\n",
    "img16_scaled = (img16/10000).astype(np.float64)\n",
    "img22_scaled = (img22/10000).astype(np.float64)\n",
    "\n",
    "img16_scaled.dtype\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1484b2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(img16_scaled[3]) #displays the array with the re-scaled pixel values for band 4(NIR) of year 2016"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eff1a88",
   "metadata": {},
   "source": [
    "Now, we calculate the NDVI for both years. To do so, we apply the formula NDVI = (NIR) -(Red) / (NIR) + (Red) for our code. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5554a89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndvi16 = (img16_scaled[3]-img16_scaled[2]) / (img16_scaled[3] + img16_scaled[2]) #calculates the NDVI ()\n",
    "ndvi22 = (img22_scaled[3]-img22_scaled[2]) / (img22_scaled[3] + img22_scaled[2]) #calculates the NDVI ()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e39b270",
   "metadata": {},
   "source": [
    "The next lines of code display the NDVI imagery. We have set the vmin and vmax to -1 and 1 as the NDVI values ranges between -1 and 1. To display the NDVI for year 2022, exchange the first argument of ax.imshow() from \"ndvi16\" to \"ndvi22\". Make sure you also exchange the name of the map when you save the figure. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3bb6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "myCRS = ccrs.UTM(35) \n",
    "xmin, ymin, xmax, ymax = dataset22.bounds #as both images have the same bounds we can just pick one year\n",
    "fig, ax = plt.subplots(1, 1, figsize=(5, 5), subplot_kw=dict(projection=myCRS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3443b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax.imshow(ndvi16, cmap=\"brg\",vmin=-1, vmax=1, transform=myCRS, extent=[xmin, xmax, ymin, ymax]) #vmin and vmax bc NDVI is between -1 and 1\n",
    "fig \n",
    "fig.savefig('map3.png', bbox_inches='tight', dpi=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88c3755",
   "metadata": {},
   "source": [
    "Finally, we calculate the difference of the NDVI between year 2016 and 2022. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ad7a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndvi_diff = ndvi16 - ndvi22\n",
    "print(ndvi_diff.min(), ndvi_diff.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b022b840",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax.imshow(ndvi_diff, cmap=\"rainbow\",vmin=-1, vmax=1, transform=myCRS, extent=[xmin, xmax, ymin, ymax]) #displays the NDVI difference\n",
    "fig\n",
    "fig.savefig('map6.png', bbox_inches='tight', dpi=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d8f24a",
   "metadata": {},
   "source": [
    "CONGRATULATIONS! You have reached the end of my script and can now enjoy the sunny weather outside. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51203b5",
   "metadata": {},
   "source": [
    "PS: Several quibbeling remained that I sadly could not solve. \n",
    "First, I was wondering how I could make a function so that I can always apply methods to both images: img16 and img22. I thought to make a list of the datasets (see function below). Making a list of the loaded images did not solve the problem either. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661718f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset_list = [dataset16, dataset22]\n",
    "\n",
    "#for i in dataset_list:\n",
    "    #image = dataset_list[i].read()\n",
    "    #print(image)\n",
    "#this did not work, because the list indices must be integers or slices, not DatasetReader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dcd981d",
   "metadata": {},
   "source": [
    "Secondly, I was wondering how I could crop the image in a way that would only load the image for the window around the mining site located at long/lat decimal -1.0333 and 27.7333. I checked the image and figured that that spatial location would correspond roughly to a quarter of the height (row) and half the width (column) of the original image. I thus tried the following code, but that does not seem to be the window/spatial location I wanted. I also tried with the coordinates directly, but that did not work. So I am wondering how one could clip/crop the window directly around the decimal coordinates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677243d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#centeri, centerj = img16.height//4, img16.width//2 \n",
    "#centerx, centery = img16.transform * (centerj, centeri) # note the reversal here, from i,j to j,i\n",
    "#top, lft = img16.index(centerx-6000, centery+6000)\n",
    "#bot, rgt = img16.index(centerx+6000, centery-6000)\n",
    "#subset = img16.read(window=((top, bot), (lft, rgt)))\n",
    "\n",
    " #I tried the following, but that did not work either:\n",
    "\n",
    "#centerx, centery = img16.index(-1.0333, 27.7333)\n",
    "#top, lft = img16.index(centerx-9000, centery+9000)\n",
    "#bot, rgt = img16.index(centerx+9000, centery-9000)\n",
    "#subset = img16.read(window=((top, bot), (lft, rgt)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
